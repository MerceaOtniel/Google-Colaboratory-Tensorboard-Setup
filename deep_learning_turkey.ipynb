{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep_learning_turkey.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/MerceaOtniel/Google-Colaboratory-Tensorboard-Setup/blob/master/deep_learning_turkey.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "9mLVqxjPEg4W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "THESE PARAMETERS WILL BE USED FOR SETTING THE SAVING PATH. FURTHERMORE, YOU WILL BE ABLE TO MODIFY THE OPTIONS TO LOAD THE MODEL FROM THAT PATH OR TO SAVE A MODEL TO IT.\n",
        "DONT FORGET TO RUN THIS WHEN YOU MODIFY THE VALUES, OTHERWISE THE MODIFICATION WILL NOT AFFECT THE PROGRAMM.\n",
        "FOR SAVING/LOADING ORTHER DATA(LIKE PHOTOS, GRAPHS, ETC) YOU WILL NEED TO WRITE THE FUNCTIONALITY FOR YOURSELF. \n",
        "THESE VARIABLES ONLY AFFECTS THE LOCATION FOR SAVING/LOADING THE MODEL(WHICH YOU WILL NEED A LOT WHEN YOU DO NOT WANT TO LOSE THE WEIGHTS OF THE MODEL)."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AG8Ssjf6D0-a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# set this to true in order to load the model\n",
        "wantToLoadModel = False        \n",
        "# set this to true in order to save your model\n",
        "wantToSaveModel = True            \n",
        "\n",
        "\n",
        "# specify the folder to be created for this project\n",
        "directory=\"drive/app\"          \n",
        "# specify the name of the file to be created.  .h5 extension is required\n",
        "fileName=\"modelweigh.h5\"          "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zmozdmTiY748",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "THIS COMMAND WILL INITIALIZE EVERYTHING FOR MOUNTING THE DRIVE (USEFUL FOR SAVING YOUR MODELS OR LOADING OTHER THINGS LIKE TRAINING DATA).\n",
        "YOU WILL BE ASKED TO INSERT A CODE(YOU WILL RECEIVE ONE LINK WHICH WILL GIVE YOU THE FIRST CODE AND AFTER THAT YOU WILL RECEIVE A SECOND LINK WITH ANOTHER CODE AND YOU WILL BE REQUIRED TO ENTER IT). \n",
        "THE CODES AND THE LINKS ARE DIFFERENT. DO NOT INPUT THE FIRST CODE BOTH TIMES.\n",
        "SOMETIMES YOU DO NOT RECEIVE ANY LINK. WHEN THIS HAPPENS IT MEANS THAT YOU HAVE ALREADY INSTALLED IT AND NO FURTHER INSTALLING IS NEEDED.\n",
        "\n",
        "ON SUCCESS YOU WILL RECEIVE THE OUTPUT \"Access token retrieved correctly.\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ee7649zUHizK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ke5olUSlHyYX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CREATING THE PATH THAT YOU SPECIFIED ABOVE. IF IT ALREADY EXISTS THEN IT WILL NOT OVERWRITE IT.\n",
        "THIS COMMAND WILL UNMOUNT EVERYTHING THAT IS CURRENTLY MOUNTED AND AFTER IT WILL MOUNT THE DRIVE (YOU NEED TO SPECIFY THE PATH YOU WANT TO MOUNT...IN MY CASE IT WAS drive/app).\n",
        "\n",
        "\n",
        "ON SUCCESS YOU WILL SEE THE LOWEST DIRECTORIES IN YOUR DRIVE, FOR EXAMPLE IN MY CASE THIS IS WHAT I SEE:\n",
        "\n",
        "2050_05_07_17_01_08 (27c63e75).mp4    \n",
        "2120_05_07_17_01_08.mp4\n",
        "ALOHAHAHAH.mp4\n",
        "Untitled0.ipynb\n",
        "Untitled.mov\n",
        "..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sGyr5n8LA--y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "if wantToSaveModel:\n",
        "  \n",
        "  fullPath=directory+\"/\"+fileName\n",
        "  if not os.path.exists(fullPath): #check to see if the path exists...if it doesn't exist a new path is created\n",
        "      os.makedirs(directory)\n",
        "      open(fullPath, 'w').write(\"doesn't matter\")\n",
        "     \n",
        "!fusermount -u drive\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive -o nonempty\n",
        "!ls drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "INGcKuBxI8O7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "YOU WILL RUN THE CODE HERE. BEFORE THE TRAINING YOU WILL SEE A LINK SIMILAR TO THIS \"http://487f6421.ngrok.io\". YOU NEED TO CLICK IT FOR ACCESSING TENSORBOARD.\n",
        "AFTER THE TRAINING BEGINS YOU WILL RECEIVE FEEDBACK EVERY 30 SECONDS.\n",
        "IF YOU WANT TO KEEP THE LOGS OF THE OLD RUNS THEN YOU NEED TO DELETE THE LINE \"!rm -rf log\".\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FDKMLkpfSksY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##########################################################################################################################################\n",
        "##################### DO NOT DELETE THIS!!!!!. IT PROVIDES THE LINK FOR ACCESSING TENSORBOARD. DO NOT DELETE THIS!!!!##################### \n",
        "!rm -rf ngrok-stable-linux-amd64.zip\n",
        "!rm -rf ngrok\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "!rm -rf log   #Delete this if you want to keep the logs of the old runs\n",
        "LOG_DIR = './log'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"\n",
        "    \n",
        "##################### DO NOT DELETE THIS!!!!!. IT PROVIDES THE LINK FOR ACCESSING TENSORBOARD. DO NOT DELETE THIS!!!!#####################    \n",
        "##########################################################################################################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras import regularizers\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "import numpy as np\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from IPython.display import clear_output\n",
        "import sys\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "\n",
        "K.clear_session() #used to delete the session in order to run the program multiple times\n",
        "\n",
        "\n",
        "#############################\n",
        "\"\"\"Global variables\"\"\"\n",
        "\n",
        "#The path where the model will be saved (you may need to specify your own path). If wantToSaveModel and wantToLoadModel are not set then this will not affect the programm.\n",
        "filepath=fullPath    \n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 1200\n",
        "##############################\n",
        "\n",
        "\n",
        "\n",
        "################################################################################################\n",
        "\"\"\"Auxiliary functions for giving runtime information and plotting them during each epoch. Moreover, the callback to Tensorboard is provided here\"\"\"\n",
        "\n",
        "\n",
        "# The events will be saved in ./log which is the folder that tensorboard uses to retrieve the data\n",
        "tbCallBack = TensorBoard(log_dir='./log', histogram_freq=1,                 \n",
        "                         write_graph=True,                                  \n",
        "                         write_grads=True,\n",
        "                         batch_size=batch_size,\n",
        "                         write_images=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class PlotLearning(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.i = 0\n",
        "        self.x = []\n",
        "        self.losses = []\n",
        "        self.val_losses = []\n",
        "        self.acc = []\n",
        "        self.val_acc = []\n",
        "        self.fig = plt.figure()\n",
        "        \n",
        "        self.logs = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        \n",
        "        self.logs.append(logs)\n",
        "        self.x.append(self.i)\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.val_losses.append(logs.get('val_loss'))\n",
        "        self.acc.append(logs.get('acc'))\n",
        "        self.val_acc.append(logs.get('val_acc'))\n",
        "        self.i += 1\n",
        "        f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)\n",
        "        \n",
        "        clear_output(wait=True)\n",
        "        \n",
        "        ax1.set_yscale('log')\n",
        "        ax1.plot(self.x, self.losses, label=\"loss\")\n",
        "        ax1.plot(self.x, self.val_losses, label=\"val_loss\")\n",
        "        ax1.legend()\n",
        "        \n",
        "        ax2.plot(self.x, self.acc, label=\"accuracy\")\n",
        "        ax2.plot(self.x, self.val_acc, label=\"validation accuracy\")\n",
        "        ax2.legend()\n",
        "        \n",
        "        plt.show();\n",
        "        \n",
        "plot = PlotLearning()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class PlotLosses(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.i = 0\n",
        "        self.x = []\n",
        "        self.losses = []\n",
        "        self.val_losses = []\n",
        "        \n",
        "        self.fig = plt.figure()\n",
        "        \n",
        "        self.logs = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        \n",
        "        self.logs.append(logs)\n",
        "        self.x.append(self.i)\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.val_losses.append(logs.get('val_loss'))\n",
        "        self.i += 1\n",
        "        \n",
        "        clear_output(wait=True)\n",
        "        plt.plot(self.x, self.losses, label=\"loss\")\n",
        "        plt.plot(self.x, self.val_losses, label=\"val_loss\")\n",
        "        plt.legend()\n",
        "        plt.show();\n",
        "        \n",
        "plot_losses = PlotLosses()\n",
        "\n",
        "\n",
        "\n",
        "# Saving the weights of the model\n",
        "if wantToSaveModel:\n",
        "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max') # this callback will save the best model in the given path\n",
        "    callbacksList=[plot_losses,plot,checkpoint,tbCallBack]\n",
        "else:\n",
        "    callbacksList=[plot_losses,plot,tbCallBack]\n",
        "\n",
        "#########################################################################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##########################################################################################################\n",
        "\"\"\"Setup data\"\"\"\n",
        "(x_train, y_train), (x_test, y_test) =cifar10.load_data()\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "x_train = np.reshape(x_train, (50000, 32*32*3))\n",
        "x_test = np.reshape(x_test, (10000, 32*32*3))\n",
        "############################################################################################################\n",
        "\n",
        "\n",
        "\n",
        "#############################################################################################################\n",
        "\"\"\"Setup model\"\"\"\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(units=500, input_dim=32*32*3,activation=\"relu\"))\n",
        "model.add(Dropout(0.20))\n",
        "model.add(Dense(units=500, input_dim=32*32*3,activation=\"relu\"))\n",
        "model.add(Dropout(0.20))\n",
        "model.add(Dense(units=500, input_dim=32*32*3,activation=\"relu\"))\n",
        "model.add(Dropout(0.20))\n",
        "model.add(Dense(units=500, input_dim=32*32*3,activation=\"relu\"))\n",
        "model.add(Dropout(0.20))\n",
        "model.add(Dense(units=10, activation=\"softmax\"))\n",
        "\n",
        "##############################################################################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "###############################################################################################################\n",
        "\"\"\"Run Model\"\"\"\n",
        "\n",
        "\n",
        "# Loading the weights of the model\n",
        "if wantToLoadModel:\n",
        "      model.load_weights(filepath) #use it only when you want to load a model \n",
        "\n",
        "    \n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              #optimizer=keras.optimizers.RMSprop(lr=0.001 ), \n",
        "              optimizer=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0, amsgrad=False),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history=model.fit(x_train, y_train,\n",
        "         batch_size=batch_size,\n",
        "         epochs=epochs,\n",
        "         verbose=1,\n",
        "         validation_split=0.2,\n",
        "         callbacks=callbacksList,\n",
        "         shuffle=True)\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "#######################################################################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "########################################################################################################\n",
        "\"\"\"Plot graphs at end of the training process\"\"\"\n",
        "\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "print(history.history.keys())\n",
        "#  \"Accuracy\"\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "# \"Loss\"\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "########################################################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FyCPSFjxG2qN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "USE THIS COMMAND TO OBTAIN THE PIDS OF THE PROCESSES THAT HAVE BEEN STARTED WHEN TENSORBOARD HAS BEEN INITIALIZED AND KILL THEM. \n",
        "IT WILL DELETE THE FILES THAT HAVE BEEN CREATED DURING THIS SESSION (USEFUL WHEN YOU WANT TO CLEAN THE DRIVE).\n",
        "IF YOU GET \"THE USAGE SCREEN\" WHEN RUNNING KILL IT MEANS THAT ALL THE PROCESSES(OR SOME OF THOSE PROCESSES) CREATED BY TENSORBOARD HAVE BEEN ALREADY KILLED.\n",
        "\n",
        "IT IS NOT MANDATORY TO EXECUTE THIS BUT IS WILL CLEAN YOUR DRIVE AND KILL THE PROCESSES THAT HAVE BEEN STARTED BY TENSORBOARD."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zJSiVsG9U1vY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pid1 = !ps aux | grep tensorboard |  grep -v \"grep\" | grep \"/usr/bin/python2 /usr/local/bin/tensorboard --logdir ./log --host 0.0.0.0 --port 6006\" | awk '{print $2}' \n",
        "pid2 = !ps aux | grep ngrok | grep -v \"grep\" | grep \"./ngrok http 6006\" | awk '{print $2}'\n",
        "!kill $(echo $pid1 | cut -d \"[\" -f2 | cut -d \"]\" -f1) \n",
        "!kill $(echo $pid2 | cut -d \"[\" -f2 | cut -d \"]\" -f1) \n",
        "!rm -rf ngrok-stable-linux-amd64.zip\n",
        "!rm -rf ngrok\n",
        "!rm -rf log\n",
        "!rm -rf datalab/adc.json\n",
        "!rm -rf Graph\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}